\section{The global impact of microbial pathogens}

The Global Burden of Disease (GBD) 2019 study reported that microbial pathogens are responsible for more than 400 million years of life lost annually across the globe, a higher burden than either cancer or cardiovascular disease \citep{vos_global_2020}. In particular, lower respiratory infections, diarrhoeal diseases, HIV/AIDS and tuberculosis were amongst the five leading causes of of global total years of life lost. More recently, the COVID-19 pandemic, declared as such by the World Health Organization (WHO) on 11 March 2020 after the emergence and global spread of the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), and as of January 2022 has cause more than 5.63 million deaths worldwide \citep{ritchie_coronavirus_2020}, making it one of the deadliest pandemics in history. Coronavirus have been responsible for three of the eighteen major pandemics registered throughout modern history \citep{piret_pandemics_2021}, all occurring after the year 2000. \textit{Yersinia pestis}, responsible for three pandemics of plague, \textit{Vibrio cholerae}, with seven cholera pandemics, and Influenza A virus, the causative agent of five flu pandemics, are responsible for the remaining ones, with Influenza being the only other pathogen with a pandemic registered after 2000. Recent decades have also witnessed the emergence of additional virulent pathogens, including the Ebola virus, West Nile virus, Dengue virus and Zika virus, particularly in lower-income countries.

In addition to the emergence of virulent pathogens, the rise of antimicrobial resistance (AMR) poses a major threat to human health around the world. In 2019 there were an estimated 4·95 million deaths associated with bacterial AMR \citep{murray_global_2022}. In 2017, the WHO released The Global Priority Pathogens (GPP) list \citep{organization_prioritization_2017} to guide discovery, research and development of new antibiotics for drug-resistant bacterial infections. Besides tuberculosis, the global priority due to being the most common and lethal airborne AMR disease worldwide today, responsible for 250 000 deaths each year, it includes 12 groups of pathogens in three priority categories: 

\begin{itemize}
  \item{\textbf{Critical priority}}
  \begin{itemize}
    \item{carbapenem-resistant \textit{Acinetobacter baumannii}}
    \item{carbapenem-resistant \textit{Pseudomonas aeruginosa}}
    \item{carbapenem-resistant, third generation cephalosporin-resistant \textit{Enterobacteriaceae}} 
  \end{itemize}
  \item{\textbf{High priority}}
  \begin{itemize}
    \item{vancomycin-resistant \textit{Enterococcus faecium}}
    \item{vancomycin-resistant, methicillin-resistant \textit{Staphylococcus aureus}}
    \item{clarithromycin-resistant \textit{Helicobacter pylori}}
    \item{fluoroquinolone-resistant \textit{Campylobacter} species}
    \item{fluoroquinolone-resistant \textit{Salmonella} species}
    \item{fluoroquinolone-resistant, third generation cephalosporin-resistant, \textit{Neisseria gonorrhoeae}}
  \end{itemize}
  \item{\textbf{Medium priority}}
    \begin{itemize}
    \item{penicillin-non-susceptible \textit{Streptococcus pneumoniae}}
    \item{ampicillin-resistant \textit{Haemophilus influenzae}}
    \item{fluoroquinolone-resistant \textit{Shigella} species} 
  \end{itemize}
\end{itemize}


Clinical microbiology is a discipline focused on rapidly characterising pathogen samples in order to direct the management of individual infected patients (diagnostic microbiology) and monitor the epidemiology of infectious disease (public health microbiology), including the detection of outbreaks and infection prevention. Globally, ... FINANTIAL BURDEN!


\subsection{Current standards for diagnostic and public health in clinical microbiology}

The past few decades have seen a major revolution in the operation of microbial laboratories, driven by the development of molecular technologies and ways to make these accessible, namely amplification-based polymerase chain reaction (PCR), matrix-assisted laser desorption/ionisation - time of light (MALDI-TOF), DNA-microarray-based hybridisation technology and T2 Magnetic Resonance (T2MR). These are used in conjunction with traditional techniques such as microscopy, culture and serology, not fully replacing them. Application of these methods differs by suspected infection type: bacterial, viral, fungal or parasitic.

\subsubsection{Bacterial infections}

For patients with bacterial infections, the crucial steps are (1) to grow an isolate from a specimen, (2) identify its species, and (3) determine its pathogenic potential and test its susceptibility to antimicrobial drugs  \citep{didelot_transforming_2012}. Together this information facilitates the specific and rational treatment of patients. For public health purposes, knowledge also needs to be gained about (4) the relatedness of the pathogen to other strains of the same species to investigate transmission routes and enable the recognition of outbreaks \citep{foxman_choosing_2005}. Traditionally, all of these steps rely on the isolation of the pathogen through culture, followed by a multi-step process that can take days to weeks before obtaining results, depending on the fastidiousness of the organism and if it can be cultured. 

Choosing an appropriate bacterial typing technique for epidemiological studies depends on the resources available and the minimum intended resolution, ranging from DNA fingerprinting to multilocus sequence typing, Pulsed-field gel electrophoresis and Sequence-based typing \citep{allerberger_molecular_2012,foxman_choosing_2005}. DNA macrorestriction analysis by pulsed field gel electrophoresis (PFGE), which revolutionised precise separation of DNA fragments, became the most widely implemented DNA fingerprinting technique \citep{allerberger_molecular_2012}, becoming the golden standard for bacterial typing \citep{neoh_pulsed-field_2019} .

In the early 2000s, Multilocus sequence typing (MLST) was proposed as a portable, universal, and definitive method for characterising bacteria \citep{maiden_multilocus_2006}. Instead of enzyme restriction of bacteria DNA, separation of the restricted DNA bands using a pulsed-field electrophoresis chamber, followed by clonal assignment of bacteria based on PFGE banding patterns, MLST relies on the amplification through PCR sequences of internal fragments of house-keeping genes (usually 5 to 7), approximately 450-500 basepairs (bp) in size, followed by its the sequence, usually my Sanger methods. For each house-keeping gene, the different sequences present within a bacterial species are assigned as distinct alleles and, for each isolate, the alleles at each of the (usually) seven loci define the allelic profile or sequence type \citep{larsen_multilocus_2012}. As with PFGE, different schemes, defining what house-keeping gene fragnments are used, are available depending of the species. Unlike PFGE, the provision of freely accessible, curated databases of MLST nucleotide sequence data enables the direct comparison of bacterial isolates, providing the basis of a common language for bacterial typing \citep{maiden_multilocus_2006}. MLST schemes for over 100 organisms having been published and made freely available (\url{https://pubmlst.org/organisms}, \cite{jolley_open-access_2018}) 


Depending on the organism identified, further and/or particular typing schemes can be applied. For \textit{S. pneumoniae}, one of the pathogens listed in the WHO's GPP list, the typing of the polysaccharide capsule, usually through Quellung reaction, is paramount for disease surveillance and pre- and post-pneumococcal vaccine evaluation as the capsule, with over 90 serotypes reported, is the dominant surface structure of the organism and plays a critical role in virulence \citep{jauneikaite_current_2015, paton_streptococcus_2019}. For the \textit{Salmonella} species, also in the GPP list, the serotype is usually determined by agglutination of the bacteria with specific antisera to identify variants of somatic (O) and flagella (H) antigens that, in various combinations, characterise more than 2600 reported serotypes \citep{diep_salmonella_2019}.

\subsubsection{Viral infections}

The traditional approaches to laboratory diagnosis of viral infections have been (1) direct detection in patient material of virions, viral antigens, or viral nucleic acids, (2) isolation of virus in cultured cells, followed by identification of the isolate, and (3) detection and measurement of antibodies in the patient’s serum (serology). \citep{burrell_laboratory_2017}

\subsubsection{Fungal infections}

\subsubsection{Parasitic infections}

Currently, the detection and diagnosis of parasite infections rely on several laboratory methods in addition to clinical symptoms, clinical history, travel history, and geographic location of patient. serology-based assays, MOLECULAR-BASED ASSAYS	, PROTEOMICS, microscopy  \citep{ndao_diagnosis_2009}
    %\item The plethora of new antiviral agents and a more sophisticated understanding of how these should be used;
    %\item An increased awareness of the clinical value of, and demand for, prompt information about viral loads, viral sequence data, and antiviral resistance information.


\section{A genomic approach to clinical microbiology}

Since the publication of the first complete microbial genome a quarter of a century ago, that of the bacterium \textit{Haemophilus influenzae} \citep{hood_dna_1996}, genomics has transformed the field of microbiology, and in particular its clinical application.  

\subsection{Sequencing}

\subsection{The role of bioinformatics}


\section{Metagenomics}

\section{Bioinformatic Analysis for Shotgun Metagenomics}

Shotgun metagenomics can offer relatively unbiased pathogen detection and characterisation, potentially able to provide genotyping, antimicrobial resistance and virulence profiling in a single methodological step. This comes with the cost of producing massive amounts of information that require expert handling and processing, as well as capable computational infrastructures. 
One of the biggest challenges when dealing with metagenomic data is the lack of golden standards, although major efforts are being made on the standardisation and assessment of software, both commercial and open source \cite{} (Angers-Loustau et al., 2018; Gruening et al., 2018; Sczyrba et al., 2017: Couto et al., 2018). A plethora of open source tools are available specifically for metagenomic data, both short and long read data, and several combinations of these tools can be used to characterize the causative agent in a patient's infection in a fraction of time required by the traditional methods. Alongside, there are several commercial alternatives, such as CLC Genomics Workbench (QIAGEN Bioinformatics), Taxonomer (Flygare et al., 2016) and BaseSpace (Illumina), that offer ready to use complete workflows at the cost of lack of transparency, reproducibility and control in the analysis.
There are several steps that can be implemented to ensure the transparency and reproducibility of the chosen workflow. Favouring open-source tools, with clear documentation describing the methodology implemented, and stating the version of the software used and which parameters were used enables the comparison of results. This can be simplified by containerizing all the software tools with one of the many solutions available, like Docker (https://www.docker.com/) or Singularity (Kurtzer et al., 2017). The use of workflow managers, like nextflow (Tommaso et al., 2017) or the Galaxy Project (Afgan et al., 2016), will push reproducibility to the next level by taking advantage of the containerization and scalability, enabling the workflow to be executed with the exact same parameters in the same conditions in a multitude of different environments. The FlowCraft project (https://github.com/assemblerflow/flowcraft) leverages the combination of Nextflow and docker/singularity containers to assemble, monitor and report scientific pipelines created from the combination of pre-built components, many of them supporting metagenomic analysis.
Additional difficulties of metagenomic data are the overpowering quantities of host DNA that are often sequenced (Couto et al., 2018), making the microbial community close to undetectable, the presence of contaminants, from the bench process to the biota, and the cost associated with this methodology. They account for major caveats and must be made aware of when analysing the data.
The basic strategies for analysing metagenomic data can be simplified in the scheme in Figure 1. One of the biggest challenges when doing metagenomic analysis is differentiating between colonization and infection and to successfully discriminate between a potential pathogen and background microbiota. In the latter, when analysing samples from presumably sterile sites, like CSF and blood, it is safe to assume that all organisms found are of interest. In locations with a microbiota, the use of spiked metagenomic samples as positive control might guide the detection of the possible pathogens by comparing relative abundance between the samples. The inclusion of negative controls is essential for the correct identification of contaminants in the taxonomic results, whether originated from the sample collection, handling or sequencing process. These controls should be processed similarly to the samples and the taxonomic results should be filtered out from the final reports. 

\subsection{Quality Assessment and Quality Control}
Quality assessment and control is a basal step to any analysis, and aims to remove and/or filter low quality and low complexity reads, trim adapters, and remove host sequences from the samples’ raw data. There are many tools available but the most commonly used are FastQC (Babraham Bioinformatics) for quality control, followed by Trimmomatic (Bolger et al., 2014) or Cutadapt (Martin, 2011) to trim and/or filter adaptors, low quality and low complexity sequences. For long read sequencing, tools like NanoPlot and NanoStats (De Coster et al., 2018), Porechop (https://github.com/rrwick/Porechop) and Filtlong (https://github.com/rrwick/Filtlong) can perform basic quality assessment and control, adapter trimming and low quality trimming respectively. 
The removal of host sequences is usually done through mapping. Bowtie2 (Langmead & Salzberg, 2012) is usually the go-tool for this process, specially as pre-build indexes of the human genome are available on-line (https://support.illumina.com/sequencing/sequencing\_software/igenome.html). The same approach can be used to remove contaminants present in the negative control by using it as reference for mapping. Alternatively for long read, minimap 2 (Li, 2018) can map long reads to large reference genomes, such as hg19, and the unmapped reads can be subsequently filtered with Samtools (Li et al., 2009). 

\subsection{Direct Taxonomic Assignment and Characterization}
An important information that can be retrieved directly from the quality controlled read data is the relative abundance of the detected organisms. Kraken (Wood & Salzberg, 2014) and Bracken (Lu et al., 2017), Midas (Nayfach et al., 2016), Kaiju (Menzel et al., 2016) and MetaPhlAn 2 (Truong et al., 2015) are all examples of taxonomic classifiers for short-read raw sequencing data that provide information on relative abundance. All tools provide a reference database. Kraken offers several pre-built databases constructed from complete bacterial, archaeal, and viral genomes in RefSeq (as of Oct. 18, 2017), known as MiniKraken, that range in size to accommodate limited computational resources, as well as providing the option to build the standard database given that the required computational resources are met. Midas and MetaPhlAn also provide a default pre-built database, with resolution down to strain level. Kaiju differs from the other tools by using a protein reference database but no pre-built version is available, requiring significant resources to build and index the database pre-use. 
The long read data can be treated as single-end fastq, after proper conversion in the basecalling process. All tools mentioned accommodate classification of single-end files. 
16S classification can also be performed, for validation purposes, by extracting the reads of interest through HMMER (Wheeler & Eddy, 2013) and then perform a traditional OTU analysis with Quiime2 (https://qiime2.org/) or MapSEQ (Rodrigues et al., 2017).  
For virulence gene detection and antimicrobial resistance characterization a mapping approach, with an adequate database, is usually followed, using as reference the Virulence Factors Database (Chen et al., 2016), and ResFinder (Zankari et al., 2012) or CARD (Jia et al., 2017) for antimicrobial resistance gene detection. Besides mapping, other strategies have been applied, like Mash Screen (Ondov et al., 2016), that offer similar results in a faster way.  Similar strategies can be applied to plasmid detection by using the PlasmidFinder (Carattoli et al., 2014) or RefSeq plasmid (O’Leary et al., 2016) databases. The minimap 2 tool (Li, 2018) is a good alternative to map long-read data to any of the resistance and virulence databases mentioned. 
It is possible to genotype the bacterial population in a metagenomic sample, but only for short-read sequencing data.  MetaMLST (Zolfo et al., 2017) reconstructs the MultiLocus Sequence Typing (MLST) loci directly from the sequencing data and provides a pre-built database for the analysis.

\subsection{Metagenome Assembly}
Several limitations arise when using just the sequencing data. Although relatively fast and providing quantitative information, it’s strictly dependent on the content of the databases used. In addition it lacks context information, as linking the characterizing information to a given identified organism isn’t possible. 
Longer sequences are more informative than shorter sequencing data and can provide a more complete picture of the microbial community in a given samples. Several dedicated metagenomic assembly tools are available, such as metaSPAdes (Nurk et al., 2017)  and MegaHIT (Li et al., 2015). These tools, in comparison to single-cell data assemblers, are better at dealing with the combination of intragenomic and intergenomic repeats and uneven sequencing coverage (Olson et al., 2017). Assembler using multiple k-mers, like the ones suggested, substantially outperform single k-mer assemblers, and smaller k-mers improve the recovery of low-abundance genomes, larger k-mer lead to a better recovery of highly abundant ones (Sczyrba et al., 2017). 
For long-read data, no dedicated metagenomic assembler is not yet available, but several assembler for long-read data as available, including Canu (Koren et al., 2017) and Unicycler (Wick et al., 2017). The latter allows for hybrid assemblies to be constructed, combining short and long read information to produce the best assembly possible. Nevertheless, the use of non dedicated assemblers for metagenomics may come with the cost of wrongly interpret variation as error, especially in samples that contained closely related species and the construction of chimeric sequences (Teeling & Glockner, 2012) as traditional assemblers follow the basic principle that the coverage in a sample is constant. 
The assembly-based approach requires the grouping of the different contigs into bins, ideally each collecting the sequences that belong to a microorganism present in the sample. The binning process can be taxonomy dependent, relying on a database to aggregate the sequences, or independent. The independent approach has the benefit of not relying on a database, but instead it uses the composition of each sequence and coverage profiles to cluster together sequences that might belong to the same organism. These algorithms don’t require prior knowledge about the genomes in a given sample, instead relying on features inherent to the sequences in the sample. Although most binning softwares can work with single metagenomic samples, most make use of differential coverage of multiple samples to improve the binning process (Sedlar et al., 2016). It allows the handling of complex ecosystems and might be crucial when analysing samples recovered from sites with a complex microbiota. 
A comparison of five taxonomic independent binning softwares and four taxonomic binning softwares (Sczyrba et al., 2017) revealed that, for taxonomic independent approaches, MaxBin 2.0 (Wu et al., 2016) had the highest completeness and purity in the bins obtained, with ~20\% better results in comparison with the second best ranked tool. For taxonomic binning, working similarly to the direct taxonomic assignment of the sequencing data, PhyloPythiaS+ (Gregor et al., 2016) obtained better results in accuracy, completeness and purity, followed by Kraken (Wood & Salzberg, 2014) that still obtained decent results with the added benefit of very high speed of analysis, ease of use and inclusion of the pre-built databases.
The last step on the assembly methodology is the evaluation of the completeness and contamination of the bins. When using a taxonomic binner, the effects of contamination are mitigated as the sequence clustering is performed based on matches with reference database. The contaminants, if present in the database, will be separated into different bins or just added to the bin of unclassified sequences. When using a taxonomic independent binning software, the composition and abundance might not be enough to discriminate between all the organisms, with the possible result of having bins with contaminating sequences of other organisms present in the sample. CheckM (Parks et al., 2015) assesses the quality of the recovered genomes, estimating completeness and contamination by evaluating ubiquitous single-copy genes. 
Another problem with metagenomic assembly is the high number of ambiguities that fail to being resolved, mostly due to the possible presence of several strains of the same species or species that are closely related. When faced with this ambiguities the assembler usually breaks the sequence, leading to fragmented reconstructions of genomes. MetaQUAST (Mikheenko et al., 2016) that besides computing several metrics to evaluate assembly quality like number of contigs, maximum contig length, etc, also uses reference-based method, either provided by the user or by identifying the appropriate reference sequences by 16S ribosomal RNA identification, to identify mis-assemblies and structural variants. VALET (https://github.com/marbl/VALET) is a de novo pipeline for detecting mis-assemblies without the need for references, relying instead on coverage and length to do the assignment, as well as providing severa visual representations of assembly quality. After the mis-assemblies have been detected, they can be visualized in Icarus (Mikheenko et al., 2016) for metaQUAST, or IGV (interactive genome viewer) for VALET. Anvi’o (Eren et al., 2015) is an analysis and visualization platform that empowers binning refinement and genome completeness and contamination evaluation with interactive interface. 
All downstream processes used in single cell genomes can be applied to each of the resulting binned genomes, that now represent a taxonomic unit recovered from the original metagenomic sample. The typical workflow usually involves antimicrobial resistance and ccvirulence detection. Similar approaches can be used as described in the Direct Taxonomic Assignment and Characterization section by using alignment methods, such as BLAST (Altschul et al., 1990) or DIAMOND (Buchfink et al., 2015), to compare against the Virulence Factors Database, and the ResFinder or CARD databases. Genotyping can be done through the mlst software (https://github.com/tseemann/mlst). The reconstructed genomes allow for the use comparative genomics against other references by using, for example, cgMLST or SNP analysis, and playing a major role in early outbreak detection. 


\subsection{Virus and Eukaryotes in Metagenomic Analysis}
One of the biggest advantages of using metagenomic methods is the detection of not only bacterial organisms, but also viral and eukaryotic pathogens. 
Besides the limitations inherent to the metagenomic process, the retrieval of viral genomes from clinical samples has added difficulties. The fragments of viral genomes are typically orders of magnitude less abundant, the viral genomes often deviate considerably from reference genomes, and the high intrapopulation viral diversity can lead to ambiguous sequence reconstruction or broken assemblies (Rose et al., 2016). Adding to this, the relatively few viral reference genomes can render classification problematic. For fungi, there’s an underrepresentation of the diversity of this group in databases as it remains understudied compared to bacterial microbiomes (Donovan et al., 2018).
Of the tools mentioned for read classification, Kraken’s MiniKraken and MetaPhlAn 2 databases is the most inclusive, including information of virus, bacteria, human and fungi. None other method of the ones described in this review provide a database as inclusive but many, such as Midas, allow the user to build custom databases although requiring very high computational power. Alternatively, the assembly based method can be implemented followed by an alignment search to a database that includes fungi and viral genomes, such as NCBI’s RefSeq (O’Leary et al., 2016) or GenBank (Benson et al., 2005). 
